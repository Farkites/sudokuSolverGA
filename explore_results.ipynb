{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils \n",
    "\n",
    "joinpath = os.path.join\n",
    "\n",
    "\n",
    "def create_dir(path): \n",
    "    if not os.path.exists(path): \n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions \n",
    "\n",
    "FITNESS_MEAN = 'fitness_mean'\n",
    "FITNESS_SD = 'fitness_sd'\n",
    "POP_SIZE = 'pop_size'\n",
    "GENS = 'gens'\n",
    "REPRESENTATION = 'representation'\n",
    "\n",
    "ANALYSIS_DIR = 'analysis/'\n",
    "create_dir(ANALYSIS_DIR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_mr = pd.read_csv('results_mr/overview_mr.csv', sep=';')\n",
    "overview_mr.insert(0, 'run_name', [f'{run}_mr' for run in overview_mr.run_id])\n",
    "#[f'{run}_mr' for run in overview_mr.run_id]\n",
    "overview_mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_dp = pd.read_csv(os.path.join('results','overview.csv'), sep=';')\n",
    "overview_dp.insert(0, 'run_name', [f'{run}_dp' for run in overview_dp.run_id])\n",
    "\n",
    "overview_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = pd.concat([overview_dp, overview_mr], axis=0)\n",
    "overview.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview['fitness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview.loc[overview.run_id == 23, ].sort_values(by='fitness_mean').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "configdims = [\n",
    "    'co_p', 'crossover', 'difficulty', 'diversity_measure','early_stopping_patience',\n",
    "    'elitism', 'epochs', 'fitness_sharing','gens', 'mu_p', \n",
    "    'mutation', 'optim', 'pop_size', 'representation','selection'\n",
    "]\n",
    "\n",
    "techdims = [\n",
    "    'user_id', 'comments'\n",
    "]\n",
    "\n",
    "iddims = [\n",
    "    'run_name', 'run_id', 'gs_id'\n",
    "]\n",
    "\n",
    "metricdims = [\n",
    "    'duration', 'fitness_mean', 'fitness_sd',\n",
    "       'stopped_early'\n",
    "]\n",
    "\n",
    "\n",
    "def analyse_config(overview, configdims, analysis_name): \n",
    "    outpath = joinpath(ANALYSIS_DIR, analysis_name)\n",
    "    create_dir(outpath)\n",
    "\n",
    "    configdims_count = overview[configdims].apply(pd.Series.nunique)\n",
    "    configdims_vary = configdims_count[configdims_count != 1].index.tolist()\n",
    "    configdims_constant = configdims_count[configdims_count == 1].index.tolist()\n",
    "\n",
    "    configdims_vary\n",
    "\n",
    "    configdims_vary = overview[configdims_vary].apply(pd.Series.unique).reset_index().rename(columns = {'index': 'param', 0: 'values'})\n",
    "    configdims_vary\n",
    "    configdims_vary.to_csv(joinpath(outpath, 'configdims_vary.csv'), index=False, sep=';')\n",
    "\n",
    "\n",
    "    configdims_constant = overview[configdims_constant].apply(pd.Series.unique).reset_index().rename(columns = {'index': 'param', 0: 'values'})\n",
    "    configdims_constant\n",
    "    configdims_constant.to_csv(joinpath(outpath, 'configdims_constant.csv'), index=False, sep=';')\n",
    "\n",
    "    info = pd.DataFrame({\n",
    "        'n_combos': [overview.shape[0]]\n",
    "    })\n",
    "\n",
    "    \n",
    "    info.to_csv(joinpath(outpath, 'info.csv'), index=False, sep=';')\n",
    "\n",
    "    \n",
    "    print(f'N_combos: {overview.shape[0]}')\n",
    "    print(f'configdims_constant:\\n{configdims_constant}')\n",
    "    print(f'configdims_vary:\\n{configdims_vary}')\n",
    "\n",
    "    \n",
    "    return configdims_vary.param.tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-involvement",
   "metadata": {},
   "source": [
    "# grid run 0 \n",
    "- compare selection \n",
    "- pop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex0 = overview.loc[overview.run_name == '0_dp']\n",
    "\n",
    "ex0.sort_values(by=[REPRESENTATION, FITNESS_MEAN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_config(ex0, configdims, 'ex0_popSize_selectio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_grid1 = pd.pivot(ex1, index=configdims_vary_g1[0:-1], columns=['representation'], values=[fitness_mean])\n",
    "repr_grid1_comp = repr_grid1.idxmin(axis=1).values.tolist()\n",
    "repr_grid1_comp\n",
    "\n",
    "repr_grid1.idxmin(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-nutrition",
   "metadata": {},
   "source": [
    "# first grid run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-disability",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-elevation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-triangle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1 = overview.loc[(overview.run_name.isin(['24_dp'])),:]\n",
    "\n",
    "configdims_vary_g1 = analyse_config(\n",
    "    overview=grid1,\n",
    "    configdims=configdims,\n",
    "    analysis_name='01_grid1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-extra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inside-maximum",
   "metadata": {},
   "source": [
    "## representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation \n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "#group = (plotdata.representation == 'maintain_init_puzzle').values\n",
    "#group = [1 if row.representation == 'maintain_init_puzzle' else 0 for row in plotdata.iterrows()]\n",
    "group = 'representation'\n",
    "h_order = grid1.groupby(group)[FITNESS_MEAN].mean().sort_values().index.tolist()\n",
    "h_order\n",
    "sns.boxplot(data = grid1, y=fitness_mean, x=group, hue=group,hue_order=h_order, ax=ax)\n",
    "#ax.set_xlabel('', rotation=45)\n",
    "ax.tick_params(labelrotation=45)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "configdims_vary_g1[0:-1]\n",
    "grid1.groupby(configdims_vary_g1[0:-1]).representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(grid1, id_vars=configdims_vary_g1[0:-1], value_vars=[fitness_mean, 'representation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_grid1 = pd.pivot(grid1.loc[grid1.run_name=='24_dp', :], index=configdims_vary_g1[0:-1], columns=['representation'], values=[fitness_mean])\n",
    "repr_grid1_comp = repr_grid1.idxmin(axis=1).values.tolist()\n",
    "repr_grid1_comp\n",
    "\n",
    "repr_grid1.idxmin(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cetris_paribus(overview_df, configdims_vary, dim, verbose=False): \n",
    "    cols_hold_constant = [d for d in configdims_vary if d not in [dim]] \n",
    "    \n",
    "    repr_grid1 = pd.pivot(overview_df, index=cols_hold_constant, columns=[dim], values=[FITNESS_MEAN])\n",
    "    if verbose: print(repr_grid1)\n",
    "    repr_grid1_comp = repr_grid1.idxmin(axis=1).values.tolist()\n",
    "    repr_grid1_comp\n",
    "\n",
    "    return repr_grid1.idxmin(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "cetris_paribus(overview_df=grid1, configdims_vary=configdims_vary_g1, dim=REPRESENTATION, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_df=grid1\n",
    "configdims_vary=configdims_vary_g1\n",
    "dim=REPRESENTATION\n",
    "\n",
    "#cetris_paribus(overview_df=grid1, configdims_vary=configdims_vary_g1, dim=REPRESENTATION)\n",
    "\n",
    "cols_hold_constant = [d for d in configdims_vary if d not in [dim]] \n",
    "cols_hold_constant\n",
    "configdims_vary\n",
    "pd.pivot(overview_df, index=cols_hold_constant, columns=[dim], values=[FITNESS_MEAN])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-dressing",
   "metadata": {},
   "source": [
    "## maintain init vs random \n",
    "- best of each\n",
    "- compare hostory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-destination",
   "metadata": {},
   "source": [
    "## ex2: explore maintain_init_position\n",
    "- subset of ex1 PLUS Sudoku specific operators (['24_dp', '12_mr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = overview.loc[\n",
    "    (overview.run_name.isin(['24_dp', '12_mr']))\n",
    "    & (overview.representation == 'maintain_init_puzzle')\n",
    "    ,:]\n",
    "\n",
    "configdims_vary_ex2 = analyse_config(ex2, configdims, 'ex2-maintain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-manchester",
   "metadata": {},
   "source": [
    "### overall variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "sns.boxplot(data=ex2, y=FITNESS_MEAN, ax=ax1)\n",
    "sns.boxplot(data=ex2, y=FITNESS_SD, ax=ax2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2.sort_values(by=FITNESS_MEAN, axis=0, ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in configdims_vary_ex2: \n",
    "    print(dim)\n",
    "    res = cetris_paribus(ex2, configdims_vary_ex2, dim)\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # plot scores \n",
    "    def plot_scores(scores, explorations_path, filename, width, height, dodge): \n",
    "        my_dpi = 200\n",
    "        fig = plt.figure(\n",
    "            figsize=(\n",
    "                #10, 8\n",
    "                width/my_dpi, height/my_dpi\n",
    "            )\n",
    "        )\n",
    "        ax = sns.pointplot(data=scores, x='model', y='mean', hue='config', alpha=.7, dodge=dodge, join=False, scale=.5)\n",
    "\n",
    "        # Find the x,y coordinates for each point\n",
    "        x_coords = []\n",
    "        y_coords = []\n",
    "        for point_pair in ax.collections:\n",
    "            for x, y in point_pair.get_offsets():\n",
    "                x_coords.append(x)\n",
    "                y_coords.append(y)\n",
    "\n",
    "        # Calculate the type of error to plot as the error bars\n",
    "        # Make sure the order is the same as the points were looped over\n",
    "        #errors = tips.groupby(['smoker', 'sex']).std()['tip']\n",
    "        #colors = ['steelblue']*2 + ['coral']*2\n",
    "        ax.errorbar(x_coords, y_coords, yerr=scores.sd, fmt=' ', zorder=-1, color='black', capsize=2)\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n",
    "                   ncol=1, mode=\"expand\", borderaxespad=0., prop={'size': 6})\n",
    "        plt.tight_layout()\n",
    "        plt.xticks(rotation=90)\n",
    "        ax.set(ylabel='mean micro f1 score')\n",
    "\n",
    "\n",
    "        plt.savefig(os.path.join(explorations_path, f'{filename}.png'), dpi=200, bbox_inches = \"tight\")\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "       \n",
    "    # generate and save plot\n",
    "    plot_scores(scores, explorations_path, 'comp_all', 1200, 1400, .4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-publisher",
   "metadata": {},
   "source": [
    "# pop size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_runs(overview, colname, values):\n",
    "    df = deepcopy(overview)\n",
    "    if not isinstance(values, list): \n",
    "        values = [values]\n",
    "    return overview.loc[overview[colname].isin(values), ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = filter_runs(overview, 'run_id', 0)\n",
    "plotdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata.loc['cat_maintain_init_puzzle'] = np.where(plotdata.representation == 'maintain_init_puzzle', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "#group = (plotdata.representation == 'maintain_init_puzzle').values\n",
    "group = [1 if row.representation == 'maintain_init_puzzle' else 0 for row in plotdata.iterrows()]\n",
    "group\n",
    "#sns.boxplot(data = plotdata, y=fitness_mean, x=group, hue=group, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in plotdata.iteritems(): \n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata[(plotdata.fitness_mean < 40) & (plotdata.pop_size == 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview.loc[overview['run_id'] in [0] , ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-marriage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
